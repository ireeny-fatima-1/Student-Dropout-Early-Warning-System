# -*- coding: utf-8 -*-
"""smit project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HXlRc7YtplJ7MGJNZvl9luqOYRvrOV13

###**Step 1: data handeling**
**1:Load Data and Prepare Features**
"""

import pandas as pd

# Load data
data = pd.read_csv('/content/student_data.csv')
# Show the first few rows
print(data.head())

# Basic info
print(data.info())

# Summary statistics
print(data.describe())

"""**2. Check for Missing Values**"""

# Check for missing data
print(data.isnull().sum())

# If missing, decide how to handle (impute or drop)

"""**3. Understand Data Distributions**

**Visualizations help to see how data is spread:**
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Distributions of features
features = ['attendance', 'grades', 'participation', 'study_hours']

for feature in features:
    plt.figure(figsize=(6,4))
    sns.histplot(data[feature], kde=True)
    plt.title(f'Distribution of {feature}')
    plt.show()

"""**4. Explore Relationships Between Features and Dropout**

"""

# Boxplots to see how features differ by dropout status
for feature in features:
    plt.figure(figsize=(6,4))
    sns.boxplot(x='dropout', y=feature, data=data)
    plt.title(f'{feature} by Dropout Status')
    plt.show()

"""**5. Correlation Analysis**

Understanding correlations helps in feature selection:**
"""

# Correlation matrix
corr = data.corr()

# Plot heatmap
plt.figure(figsize=(8,6))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.title('Feature Correlations')
plt.show()

"""**6. Check for Imbalanced Classes**"""

# Count of dropout vs continue
print(data['dropout'].value_counts())

# Plot
sns.countplot(x='dropout', data=data)
plt.title('Dropout vs Continue')
plt.show()

"""**7. Identify Noisy or Outlier Data**"""

# Using boxplots to spot outliers
for feature in features:
    plt.figure(figsize=(6,4))
    sns.boxplot(x=data[feature])
    plt.title(f'Outlier detection for {feature}')
    plt.show()

"""**Based on EDA:**

Identify features with strong separation between dropout and continue students.

Detect noisy data or outliers that might need cleaning.

Recognize class imbalance, which might require techniques like resampling.

Consider feature engineering based on observed patterns.
"""

# Features and labels
X = data[['attendance', 'grades', 'participation']]
y = data['dropout']

"""**Data Preparation & Preprocessing**

"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import pickle

# Load your data
data = pd.read_csv('student_data.csv')

# Check for missing values
print("Missing values:\n", data.isnull().sum())

# Handle missing values if any (here assuming none, but if present, impute or drop)
# data.fillna(method='ffill', inplace=True)

# Features and target
X = data[['attendance', 'grades', 'participation']]
y = data['dropout']

# Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Save scaler for future use in app
with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

"""**Split Data and Train Model**

"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import pickle

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train model
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

"""**Train Model with Hyperparameter Tuning**

"""

# Split data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

# Initialize Logistic Regression
lr = LogisticRegression()

# Hyperparameter tuning with GridSearchCV
param_grid = {
    'C': [0.1, 1, 10, 100],
    'penalty': ['l2'],
    'solver': ['lbfgs']
}

grid = GridSearchCV(lr, param_grid, cv=5, scoring='roc_auc')
grid.fit(X_train, y_train)

print("Best parameters:", grid.best_params_)

# Evaluate on test data
best_model = grid.best_estimator_
y_pred = best_model.predict(X_test)
print("Classification report:\n", classification_report(y_test, y_pred))
print("ROC AUC score:", roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))

# Save the trained model
with open('dropout_model.pkl', 'wb') as f:
    pickle.dump(best_model, f)

"""**Save Data and Train Model**

"""

# Save the model for later use
with open('dropout_model.pkl', 'wb') as f:
    pickle.dump(model, f)

"""###**Step 2: Build a Simple Prediction Interface with Streamlit**
**Install Streamlit**
"""

pip install streamlit

"""**Building the Streamlit App for Prediction**"""

import streamlit as st
import pickle
import numpy as np

# Load saved model and scaler
with open('dropout_model.pkl', 'rb') as f:
    model = pickle.load(f)

with open('scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

st.title("Student Dropout Early Warning System")

st.write("Input early semester data:")

# User input sliders
attendance = st.slider("Attendance Rate (%)", 0, 100, 75)
grades = st.slider("Average Grades", 0.0, 100.0, 70.0)
participation = st.slider("Participation Score (1-10)", 1, 10, 5)

# When user clicks predict
if st.button("Predict Dropout Risk"):
    input_features = np.array([[attendance, grades, participation]])
    input_scaled = scaler.transform(input_features)
    prediction = model.predict(input_scaled)
    risk_status = "At Risk of Dropping Out" if prediction[0] == 1 else "Likely to Continue"
    st.write(f"Prediction: {risk_status}")

"""**Create the App Script**

**Create a file named student_dropout_app.py**
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile student_dropout_app.py
# import streamlit as st
# import pickle
# import numpy as np
# 
# # Load the trained model
# with open('dropout_model.pkl', 'rb') as f:
#     model = pickle.load(f)
# 
# st.title("Student Dropout Early Warning System")
# 
# st.write("Enter early semester student data:")
# 
# # User inputs
# attendance = st.slider("Attendance Rate (%)", 0, 100, 75)
# grades = st.slider("Average Grades", 0.0, 100.0, 70.0)
# participation = st.slider("Participation Score (1-10)", 1, 10, 5)
# 
# # Prediction button
# if st.button("Predict Dropout Risk"):
#     input_features = np.array([[attendance, grades, participation]])
#     prediction = model.predict(input_features)
#     risk_status = "At Risk of Dropping Out" if prediction[0] == 1 else "Likely to Continue"
#     st.write(f"Prediction: {risk_status}")

"""**Run the App**

**In your terminal, run**
"""

get_ipython().system('streamlit run student_dropout_app.py')





